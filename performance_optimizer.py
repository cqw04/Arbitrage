#!/usr/bin/env python3
"""
æ€§èƒ½å„ªåŒ–æ¨¡çµ„ - é€£æ¥æ± ã€æ•¸æ“šå¿«å–ã€ç•°æ­¥è™•ç†å„ªåŒ–
æä¾›å…¨é¢çš„æ€§èƒ½æå‡è§£æ±ºæ–¹æ¡ˆï¼ŒåŒ…æ‹¬å…§å­˜ç®¡ç†å’Œä¸¦ç™¼å„ªåŒ–
"""

import asyncio
import aiohttp
import time
import psutil
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Callable
from dataclasses import dataclass, field
from collections import defaultdict, deque
from abc import ABC, abstractmethod
import json
import threading
import weakref
from functools import wraps, lru_cache
import gc
from concurrent.futures import ThreadPoolExecutor

logger = logging.getLogger("PerformanceOptimizer")

@dataclass
class CacheEntry:
    """å¿«å–æ¢ç›®"""
    key: str
    value: Any
    timestamp: datetime
    ttl: float  # ç”Ÿå­˜æ™‚é–“ï¼ˆç§’ï¼‰
    access_count: int = 0
    last_access: datetime = field(default_factory=datetime.now)
    
    def is_expired(self) -> bool:
        return datetime.now() > self.timestamp + timedelta(seconds=self.ttl)
    
    def touch(self):
        """æ›´æ–°è¨ªå•ä¿¡æ¯"""
        self.access_count += 1
        self.last_access = datetime.now()

class ConnectionPool:
    """HTTPé€£æ¥æ± ç®¡ç†å™¨"""
    
    def __init__(self, max_connections: int = 100, max_connections_per_host: int = 20):
        self.max_connections = max_connections
        self.max_connections_per_host = max_connections_per_host
        self.sessions: Dict[str, aiohttp.ClientSession] = {}
        self.connection_stats = defaultdict(int)
        self.lock = asyncio.Lock()
        
        # é€£æ¥å™¨é…ç½®
        self.connector_config = {
            'limit': max_connections,
            'limit_per_host': max_connections_per_host,
            'ttl_dns_cache': 300,  # DNSå¿«å–5åˆ†é˜
            'use_dns_cache': True,
            'keepalive_timeout': 60,
            'enable_cleanup_closed': True
        }
        
        logger.info(f"âœ… é€£æ¥æ± å·²åˆå§‹åŒ–: æœ€å¤§é€£æ¥æ•¸={max_connections}, æ¯ä¸»æ©Ÿ={max_connections_per_host}")
    
    async def get_session(self, session_key: str = "default") -> aiohttp.ClientSession:
        """ç²å–æœƒè©±"""
        async with self.lock:
            if session_key not in self.sessions:
                connector = aiohttp.TCPConnector(**self.connector_config)
                
                # è¨­ç½®è¶…æ™‚
                timeout = aiohttp.ClientTimeout(
                    total=30,          # ç¸½è¶…æ™‚
                    connect=10,        # é€£æ¥è¶…æ™‚
                    sock_connect=10,   # socketé€£æ¥è¶…æ™‚
                    sock_read=20       # socketè®€å–è¶…æ™‚
                )
                
                self.sessions[session_key] = aiohttp.ClientSession(
                    connector=connector,
                    timeout=timeout,
                    headers={
                        'User-Agent': 'FundingArbitrageBot/2.0',
                        'Accept': 'application/json',
                        'Accept-Encoding': 'gzip, deflate'
                    }
                )
                
                logger.info(f"ğŸ”— å‰µå»ºæ–°æœƒè©±: {session_key}")
            
            self.connection_stats[session_key] += 1
            return self.sessions[session_key]
    
    async def close_session(self, session_key: str):
        """é—œé–‰ç‰¹å®šæœƒè©±"""
        async with self.lock:
            if session_key in self.sessions:
                await self.sessions[session_key].close()
                del self.sessions[session_key]
                logger.info(f"ğŸ”’ æœƒè©±å·²é—œé–‰: {session_key}")
    
    async def close_all(self):
        """é—œé–‰æ‰€æœ‰æœƒè©±"""
        async with self.lock:
            for session_key, session in self.sessions.items():
                await session.close()
                logger.info(f"ğŸ”’ æœƒè©±å·²é—œé–‰: {session_key}")
            
            self.sessions.clear()
            logger.info("âœ… æ‰€æœ‰é€£æ¥æ± æœƒè©±å·²é—œé–‰")
    
    def get_stats(self) -> Dict[str, Any]:
        """ç²å–é€£æ¥çµ±è¨ˆ"""
        return {
            'active_sessions': len(self.sessions),
            'max_connections': self.max_connections,
            'connection_usage': dict(self.connection_stats),
            'total_requests': sum(self.connection_stats.values())
        }

class AdvancedCache:
    """é«˜ç´šå¿«å–ç³»çµ±"""
    
    def __init__(self, max_size: int = 1000, default_ttl: float = 300):
        self.max_size = max_size
        self.default_ttl = default_ttl
        self.data: Dict[str, CacheEntry] = {}
        self.access_times = deque()  # LRUè¿½è¹¤
        self.lock = asyncio.Lock()
        
        # çµ±è¨ˆä¿¡æ¯
        self.stats = {
            'hits': 0,
            'misses': 0,
            'evictions': 0,
            'total_requests': 0
        }
        
        logger.info(f"âœ… é«˜ç´šå¿«å–å·²åˆå§‹åŒ–: æœ€å¤§å¤§å°={max_size}, é»˜èªTTL={default_ttl}ç§’")
    
    async def get(self, key: str) -> Optional[Any]:
        """ç²å–å¿«å–å€¼"""
        async with self.lock:
            self.stats['total_requests'] += 1
            
            if key not in self.data:
                self.stats['misses'] += 1
                return None
            
            entry = self.data[key]
            
            # æª¢æŸ¥éæœŸ
            if entry.is_expired():
                del self.data[key]
                self.stats['misses'] += 1
                return None
            
            # æ›´æ–°è¨ªå•ä¿¡æ¯
            entry.touch()
            self.access_times.append((time.time(), key))
            self.stats['hits'] += 1
            
            logger.debug(f"å¿«å–å‘½ä¸­: {key}")
            return entry.value
    
    async def set(self, key: str, value: Any, ttl: Optional[float] = None) -> None:
        """è¨­ç½®å¿«å–å€¼"""
        async with self.lock:
            if ttl is None:
                ttl = self.default_ttl
            
            entry = CacheEntry(
                key=key,
                value=value,
                timestamp=datetime.now(),
                ttl=ttl
            )
            
            # æª¢æŸ¥å®¹é‡é™åˆ¶
            if len(self.data) >= self.max_size:
                await self._evict_lru()
            
            self.data[key] = entry
            self.access_times.append((time.time(), key))
            
            logger.debug(f"å¿«å–è¨­ç½®: {key}, TTL={ttl}ç§’")
    
    async def delete(self, key: str) -> bool:
        """åˆªé™¤å¿«å–å€¼"""
        async with self.lock:
            if key in self.data:
                del self.data[key]
                logger.debug(f"å¿«å–åˆªé™¤: {key}")
                return True
            return False
    
    async def clear(self):
        """æ¸…ç©ºå¿«å–"""
        async with self.lock:
            self.data.clear()
            self.access_times.clear()
            logger.info("ğŸ—‘ï¸ å¿«å–å·²æ¸…ç©º")
    
    async def _evict_lru(self):
        """é©…é€æœ€å°‘ä½¿ç”¨çš„æ¢ç›®"""
        if not self.data:
            return
        
        # æ‰¾åˆ°æœ€å°‘ä½¿ç”¨çš„key
        oldest_key = None
        oldest_time = float('inf')
        
        for key, entry in self.data.items():
            if entry.last_access.timestamp() < oldest_time:
                oldest_time = entry.last_access.timestamp()
                oldest_key = key
        
        if oldest_key:
            del self.data[oldest_key]
            self.stats['evictions'] += 1
            logger.debug(f"LRUé©…é€: {oldest_key}")
    
    async def cleanup_expired(self):
        """æ¸…ç†éæœŸæ¢ç›®"""
        async with self.lock:
            expired_keys = [
                key for key, entry in self.data.items()
                if entry.is_expired()
            ]
            
            for key in expired_keys:
                del self.data[key]
            
            if expired_keys:
                logger.info(f"ğŸ§¹ æ¸…ç†éæœŸå¿«å–: {len(expired_keys)} å€‹æ¢ç›®")
    
    def get_stats(self) -> Dict[str, Any]:
        """ç²å–å¿«å–çµ±è¨ˆ"""
        hit_rate = (self.stats['hits'] / max(1, self.stats['total_requests'])) * 100
        
        return {
            'size': len(self.data),
            'max_size': self.max_size,
            'hit_rate': hit_rate,
            'hits': self.stats['hits'],
            'misses': self.stats['misses'],
            'evictions': self.stats['evictions'],
            'total_requests': self.stats['total_requests']
        }

class AsyncTaskManager:
    """ç•°æ­¥ä»»å‹™ç®¡ç†å™¨"""
    
    def __init__(self, max_concurrent_tasks: int = 50):
        self.max_concurrent_tasks = max_concurrent_tasks
        self.semaphore = asyncio.Semaphore(max_concurrent_tasks)
        self.active_tasks: Dict[str, asyncio.Task] = {}
        self.task_stats = defaultdict(int)
        self.lock = asyncio.Lock()
        
        logger.info(f"âœ… ç•°æ­¥ä»»å‹™ç®¡ç†å™¨å·²åˆå§‹åŒ–: æœ€å¤§ä½µç™¼={max_concurrent_tasks}")
    
    async def submit_task(self, task_id: str, coro, priority: int = 0) -> asyncio.Task:
        """æäº¤ç•°æ­¥ä»»å‹™"""
        async with self.semaphore:
            async with self.lock:
                # å¦‚æœä»»å‹™å·²å­˜åœ¨ä¸”æœªå®Œæˆï¼Œå…ˆå–æ¶ˆ
                if task_id in self.active_tasks and not self.active_tasks[task_id].done():
                    self.active_tasks[task_id].cancel()
                
                # å‰µå»ºæ–°ä»»å‹™
                task = asyncio.create_task(coro)
                self.active_tasks[task_id] = task
                self.task_stats['submitted'] += 1
                
                logger.debug(f"ğŸ“‹ æäº¤ä»»å‹™: {task_id}")
                
                # è¨­ç½®å®Œæˆå›èª¿
                task.add_done_callback(lambda t: self._task_done_callback(task_id, t))
                
                return task
    
    def _task_done_callback(self, task_id: str, task: asyncio.Task):
        """ä»»å‹™å®Œæˆå›èª¿"""
        try:
            if task.cancelled():
                self.task_stats['cancelled'] += 1
                logger.debug(f"âŒ ä»»å‹™å·²å–æ¶ˆ: {task_id}")
            elif task.exception():
                self.task_stats['failed'] += 1
                logger.warning(f"âš ï¸ ä»»å‹™å¤±æ•—: {task_id}, éŒ¯èª¤: {task.exception()}")
            else:
                self.task_stats['completed'] += 1
                logger.debug(f"âœ… ä»»å‹™å®Œæˆ: {task_id}")
        finally:
            # æ¸…ç†å®Œæˆçš„ä»»å‹™
            if task_id in self.active_tasks:
                del self.active_tasks[task_id]
    
    async def cancel_task(self, task_id: str) -> bool:
        """å–æ¶ˆä»»å‹™"""
        async with self.lock:
            if task_id in self.active_tasks:
                task = self.active_tasks[task_id]
                if not task.done():
                    task.cancel()
                    logger.info(f"ğŸš« ä»»å‹™å·²å–æ¶ˆ: {task_id}")
                    return True
            return False
    
    async def cancel_all_tasks(self):
        """å–æ¶ˆæ‰€æœ‰ä»»å‹™"""
        async with self.lock:
            for task_id, task in self.active_tasks.items():
                if not task.done():
                    task.cancel()
            
            logger.info(f"ğŸš« å·²å–æ¶ˆæ‰€æœ‰ä»»å‹™: {len(self.active_tasks)} å€‹")
    
    def get_stats(self) -> Dict[str, Any]:
        """ç²å–ä»»å‹™çµ±è¨ˆ"""
        return {
            'active_tasks': len(self.active_tasks),
            'max_concurrent': self.max_concurrent_tasks,
            'submitted': self.task_stats['submitted'],
            'completed': self.task_stats['completed'],
            'failed': self.task_stats['failed'],
            'cancelled': self.task_stats['cancelled']
        }

class MemoryManager:
    """å…§å­˜ç®¡ç†å™¨"""
    
    def __init__(self, max_memory_mb: int = 512):
        self.max_memory_mb = max_memory_mb
        self.process = psutil.Process()
        self.gc_stats = {
            'manual_collections': 0,
            'objects_collected': 0,
            'last_collection': None
        }
        
        logger.info(f"âœ… å…§å­˜ç®¡ç†å™¨å·²åˆå§‹åŒ–: æœ€å¤§å…§å­˜={max_memory_mb}MB")
    
    def get_memory_usage(self) -> Dict[str, Any]:
        """ç²å–å…§å­˜ä½¿ç”¨æƒ…æ³"""
        memory_info = self.process.memory_info()
        memory_percent = self.process.memory_percent()
        
        return {
            'rss_mb': memory_info.rss / 1024 / 1024,
            'vms_mb': memory_info.vms / 1024 / 1024,
            'percent': memory_percent,
            'max_memory_mb': self.max_memory_mb,
            'available_system_mb': psutil.virtual_memory().available / 1024 / 1024
        }
    
    def should_collect_garbage(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦éœ€è¦åƒåœ¾å›æ”¶"""
        memory_info = self.get_memory_usage()
        
        # å¦‚æœå…§å­˜ä½¿ç”¨è¶…é80%ï¼Œè§¸ç™¼åƒåœ¾å›æ”¶
        if memory_info['rss_mb'] > self.max_memory_mb * 0.8:
            return True
        
        # å¦‚æœç³»çµ±å¯ç”¨å…§å­˜ä½æ–¼1GBï¼Œè§¸ç™¼åƒåœ¾å›æ”¶
        if memory_info['available_system_mb'] < 1024:
            return True
        
        return False
    
    def collect_garbage(self) -> Dict[str, Any]:
        """åŸ·è¡Œåƒåœ¾å›æ”¶"""
        logger.info("ğŸ—‘ï¸ åŸ·è¡Œåƒåœ¾å›æ”¶...")
        
        before_memory = self.get_memory_usage()
        
        # åŸ·è¡Œåƒåœ¾å›æ”¶
        collected = 0
        for generation in range(3):
            collected += gc.collect(generation)
        
        after_memory = self.get_memory_usage()
        freed_mb = before_memory['rss_mb'] - after_memory['rss_mb']
        
        # æ›´æ–°çµ±è¨ˆ
        self.gc_stats['manual_collections'] += 1
        self.gc_stats['objects_collected'] += collected
        self.gc_stats['last_collection'] = datetime.now()
        
        result = {
            'objects_collected': collected,
            'memory_freed_mb': freed_mb,
            'before_memory_mb': before_memory['rss_mb'],
            'after_memory_mb': after_memory['rss_mb']
        }
        
        logger.info(f"âœ… åƒåœ¾å›æ”¶å®Œæˆ: å›æ”¶å°è±¡={collected}, é‡‹æ”¾å…§å­˜={freed_mb:.2f}MB")
        return result
    
    def get_gc_stats(self) -> Dict[str, Any]:
        """ç²å–åƒåœ¾å›æ”¶çµ±è¨ˆ"""
        return {
            'manual_collections': self.gc_stats['manual_collections'],
            'objects_collected': self.gc_stats['objects_collected'],
            'last_collection': self.gc_stats['last_collection'].isoformat() if self.gc_stats['last_collection'] else None,
            'gc_counts': gc.get_count(),
            'gc_thresholds': gc.get_threshold()
        }

class PerformanceMonitor:
    """æ€§èƒ½ç›£æ§å™¨"""
    
    def __init__(self):
        self.metrics = defaultdict(list)
        self.start_time = time.time()
        self.lock = threading.Lock()
        
        logger.info("âœ… æ€§èƒ½ç›£æ§å™¨å·²åˆå§‹åŒ–")
    
    def record_metric(self, name: str, value: float, timestamp: Optional[float] = None):
        """è¨˜éŒ„æ€§èƒ½æŒ‡æ¨™"""
        if timestamp is None:
            timestamp = time.time()
        
        with self.lock:
            self.metrics[name].append((timestamp, value))
            
            # ä¿æŒæœ€è¿‘1000å€‹æ•¸æ“šé»
            if len(self.metrics[name]) > 1000:
                self.metrics[name] = self.metrics[name][-1000:]
    
    def get_metric_stats(self, name: str, duration_seconds: int = 3600) -> Dict[str, Any]:
        """ç²å–æŒ‡æ¨™çµ±è¨ˆ"""
        cutoff_time = time.time() - duration_seconds
        
        with self.lock:
            if name not in self.metrics:
                return {}
            
            # éæ¿¾æ™‚é–“ç¯„åœå…§çš„æ•¸æ“š
            recent_data = [
                (ts, value) for ts, value in self.metrics[name]
                if ts >= cutoff_time
            ]
            
            if not recent_data:
                return {}
            
            values = [value for _, value in recent_data]
            
            return {
                'count': len(values),
                'min': min(values),
                'max': max(values),
                'avg': sum(values) / len(values),
                'latest': values[-1],
                'duration_seconds': duration_seconds
            }
    
    def get_system_metrics(self) -> Dict[str, Any]:
        """ç²å–ç³»çµ±æ€§èƒ½æŒ‡æ¨™"""
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        # ç¶²çµ¡I/O
        net_io = psutil.net_io_counters()
        
        return {
            'cpu_percent': cpu_percent,
            'memory_percent': memory.percent,
            'memory_available_mb': memory.available / 1024 / 1024,
            'disk_percent': (disk.used / disk.total) * 100,
            'disk_free_gb': disk.free / 1024 / 1024 / 1024,
            'net_bytes_sent': net_io.bytes_sent,
            'net_bytes_recv': net_io.bytes_recv,
            'uptime_seconds': time.time() - self.start_time
        }

class PerformanceOptimizer:
    """æ€§èƒ½å„ªåŒ–å™¨ä¸»é¡"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        
        # åˆå§‹åŒ–çµ„ä»¶
        self.connection_pool = ConnectionPool(
            max_connections=self.config.get('max_connections', 100),
            max_connections_per_host=self.config.get('max_connections_per_host', 20)
        )
        
        self.cache = AdvancedCache(
            max_size=self.config.get('cache_max_size', 1000),
            default_ttl=self.config.get('cache_default_ttl', 300)
        )
        
        self.task_manager = AsyncTaskManager(
            max_concurrent_tasks=self.config.get('max_concurrent_tasks', 50)
        )
        
        self.memory_manager = MemoryManager(
            max_memory_mb=self.config.get('max_memory_mb', 512)
        )
        
        self.monitor = PerformanceMonitor()
        
        # è‡ªå‹•å„ªåŒ–ä»»å‹™
        self.auto_optimize_enabled = self.config.get('auto_optimize', True)
        self.optimization_task = None
        
        logger.info("ğŸš€ æ€§èƒ½å„ªåŒ–å™¨å·²åˆå§‹åŒ–")
    
    async def start_optimization(self):
        """é–‹å§‹è‡ªå‹•å„ªåŒ–"""
        if self.auto_optimize_enabled:
            self.optimization_task = asyncio.create_task(self._optimization_loop())
            logger.info("ğŸ”„ è‡ªå‹•å„ªåŒ–å·²å•Ÿå‹•")
    
    async def stop_optimization(self):
        """åœæ­¢è‡ªå‹•å„ªåŒ–"""
        if self.optimization_task:
            self.optimization_task.cancel()
            logger.info("â¹ï¸ è‡ªå‹•å„ªåŒ–å·²åœæ­¢")
        
        await self.connection_pool.close_all()
        await self.task_manager.cancel_all_tasks()
    
    async def _optimization_loop(self):
        """å„ªåŒ–å¾ªç’°"""
        while True:
            try:
                # è¨˜éŒ„ç³»çµ±æŒ‡æ¨™
                system_metrics = self.monitor.get_system_metrics()
                self.monitor.record_metric('cpu_percent', system_metrics['cpu_percent'])
                self.monitor.record_metric('memory_percent', system_metrics['memory_percent'])
                
                # æ¸…ç†éæœŸå¿«å–
                await self.cache.cleanup_expired()
                
                # æª¢æŸ¥å…§å­˜ä½¿ç”¨
                if self.memory_manager.should_collect_garbage():
                    self.memory_manager.collect_garbage()
                
                # ç­‰å¾…ä¸‹æ¬¡æª¢æŸ¥
                await asyncio.sleep(60)  # æ¯åˆ†é˜æª¢æŸ¥ä¸€æ¬¡
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"å„ªåŒ–å¾ªç’°éŒ¯èª¤: {e}")
                await asyncio.sleep(60)
    
    async def cached_request(self, session_key: str, url: str, cache_key: Optional[str] = None,
                           ttl: Optional[float] = None, **kwargs) -> Any:
        """å¸¶å¿«å–çš„HTTPè«‹æ±‚"""
        if cache_key is None:
            cache_key = f"{session_key}:{url}"
        
        # å˜—è©¦å¾å¿«å–ç²å–
        cached_result = await self.cache.get(cache_key)
        if cached_result is not None:
            return cached_result
        
        # ç™¼é€è«‹æ±‚
        session = await self.connection_pool.get_session(session_key)
        
        start_time = time.time()
        try:
            async with session.get(url, **kwargs) as response:
                if response.status == 200:
                    data = await response.json()
                    
                    # å­˜å…¥å¿«å–
                    await self.cache.set(cache_key, data, ttl)
                    
                    # è¨˜éŒ„æ€§èƒ½æŒ‡æ¨™
                    request_time = time.time() - start_time
                    self.monitor.record_metric('request_time', request_time)
                    
                    return data
                else:
                    logger.warning(f"HTTPè«‹æ±‚å¤±æ•—: {response.status} {url}")
                    return None
        
        except Exception as e:
            logger.error(f"è«‹æ±‚éŒ¯èª¤: {e}")
            return None
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """ç²å–æ€§èƒ½æ‘˜è¦"""
        return {
            'connection_pool': self.connection_pool.get_stats(),
            'cache': self.cache.get_stats(),
            'task_manager': self.task_manager.get_stats(),
            'memory': self.memory_manager.get_memory_usage(),
            'gc_stats': self.memory_manager.get_gc_stats(),
            'system': self.monitor.get_system_metrics(),
            'request_time_stats': self.monitor.get_metric_stats('request_time'),
            'auto_optimize_enabled': self.auto_optimize_enabled
        }

# è£é£¾å™¨å’Œå·¥å…·å‡½æ•¸
def async_cached(ttl: float = 300, key_func: Optional[Callable] = None):
    """ç•°æ­¥å¿«å–è£é£¾å™¨"""
    def decorator(func):
        cache_data = {}
        
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # ç”Ÿæˆå¿«å–éµ
            if key_func:
                cache_key = key_func(*args, **kwargs)
            else:
                cache_key = f"{func.__name__}:{hash(str(args) + str(sorted(kwargs.items())))}"
            
            # æª¢æŸ¥å¿«å–
            if cache_key in cache_data:
                entry_time, result = cache_data[cache_key]
                if time.time() - entry_time < ttl:
                    return result
            
            # åŸ·è¡Œå‡½æ•¸
            result = await func(*args, **kwargs)
            
            # å­˜å…¥å¿«å–
            cache_data[cache_key] = (time.time(), result)
            
            # æ¸…ç†éæœŸæ¢ç›®
            current_time = time.time()
            expired_keys = [
                key for key, (entry_time, _) in cache_data.items()
                if current_time - entry_time > ttl
            ]
            for key in expired_keys:
                del cache_data[key]
            
            return result
        
        return wrapper
    return decorator

def monitor_performance(metric_name: str, monitor: Optional[PerformanceMonitor] = None):
    """æ€§èƒ½ç›£æ§è£é£¾å™¨"""
    def decorator(func):
        @wraps(func)
        async def async_wrapper(*args, **kwargs):
            start_time = time.time()
            try:
                result = await func(*args, **kwargs)
                return result
            finally:
                duration = time.time() - start_time
                if monitor:
                    monitor.record_metric(metric_name, duration)
        
        @wraps(func)
        def sync_wrapper(*args, **kwargs):
            start_time = time.time()
            try:
                result = func(*args, **kwargs)
                return result
            finally:
                duration = time.time() - start_time
                if monitor:
                    monitor.record_metric(metric_name, duration)
        
        return async_wrapper if asyncio.iscoroutinefunction(func) else sync_wrapper
    return decorator

def create_performance_optimizer(config_file: str = None) -> PerformanceOptimizer:
    """å‰µå»ºæ€§èƒ½å„ªåŒ–å™¨å¯¦ä¾‹"""
    
    # é»˜èªé…ç½®
    default_config = {
        'max_connections': 100,
        'max_connections_per_host': 20,
        'cache_max_size': 1000,
        'cache_default_ttl': 300,
        'max_concurrent_tasks': 50,
        'max_memory_mb': 512,
        'auto_optimize': True
    }
    
    # åŠ è¼‰é…ç½®æ–‡ä»¶
    if config_file:
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                file_config = json.load(f)
                default_config.update(file_config)
        except Exception as e:
            logger.warning(f"é…ç½®æ–‡ä»¶åŠ è¼‰å¤±æ•—ï¼Œä½¿ç”¨é»˜èªé…ç½®: {e}")
    
    return PerformanceOptimizer(default_config)

# æ¸¬è©¦å‡½æ•¸
async def test_performance_optimizer():
    """æ¸¬è©¦æ€§èƒ½å„ªåŒ–å™¨"""
    
    print("ğŸ§ª æ¸¬è©¦æ€§èƒ½å„ªåŒ–å™¨")
    
    # å‰µå»ºå„ªåŒ–å™¨
    optimizer = create_performance_optimizer()
    
    # å•Ÿå‹•å„ªåŒ–
    await optimizer.start_optimization()
    
    # æ¸¬è©¦å¿«å–è«‹æ±‚
    for i in range(5):
        result = await optimizer.cached_request(
            session_key="test",
            url="https://httpbin.org/delay/1",
            cache_key=f"test_request_{i}",
            ttl=60
        )
        print(f"è«‹æ±‚ {i}: {'æˆåŠŸ' if result else 'å¤±æ•—'}")
    
    # é¡¯ç¤ºæ€§èƒ½æ‘˜è¦
    summary = optimizer.get_performance_summary()
    print(f"æ€§èƒ½æ‘˜è¦: {json.dumps(summary, indent=2, ensure_ascii=False)}")
    
    # åœæ­¢å„ªåŒ–
    await optimizer.stop_optimization()

if __name__ == "__main__":
    asyncio.run(test_performance_optimizer()) 